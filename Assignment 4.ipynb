{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92778525",
   "metadata": {},
   "source": [
    "# Assignment 4: Pipelines and Hyperparameter Tuning (32 total marks)\n",
    "### Due: November 22 at 11:59pm\n",
    "\n",
    "### Name: Marie Howell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce31b39a",
   "metadata": {},
   "source": [
    "### In this assignment, you will be putting together everything you have learned so far. You will need to find your own dataset, do all the appropriate preprocessing, test different supervised learning models and evaluate the results. More details for each step can be found below.\n",
    "\n",
    "### You will also be asked to describe the process by which you came up with the code. More details can be found below. Please cite any websites or AI tools that you used to help you with this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf275ca7",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2b67a661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score\n",
    "from sklearn.model_selection import cross_validate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8219f163",
   "metadata": {},
   "source": [
    "## Step 1: Data Input (4 marks)\n",
    "\n",
    "Import the dataset you will be using. You can download the dataset onto your computer and read it in using pandas, or download it directly from the website. Answer the questions below about the dataset you selected. \n",
    "\n",
    "To find a dataset, you can use the resources listed in the notes. The dataset can be numerical, categorical, text-based or mixed. If you want help finding a particular dataset related to your interests, please email the instructor.\n",
    "\n",
    "**You cannot use a dataset that was used for a previous assignment or in class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2af8bd32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>male</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "1  Adelie  Torgersen            39.1           18.7              181.0   \n",
       "2  Adelie  Torgersen            39.5           17.4              186.0   \n",
       "3  Adelie  Torgersen            40.3           18.0              195.0   \n",
       "4  Adelie  Torgersen             NaN            NaN                NaN   \n",
       "5  Adelie  Torgersen            36.7           19.3              193.0   \n",
       "\n",
       "   body_mass_g     sex  year  \n",
       "1       3750.0    male  2007  \n",
       "2       3800.0  female  2007  \n",
       "3       3250.0  female  2007  \n",
       "4          NaN     NaN  2007  \n",
       "5       3450.0  female  2007  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import dataset (1 mark)\n",
    "df = pd.read_csv('/Users/marie/Desktop/ENSF611/Assignment4/penguins.csv',index_col=0)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20316765",
   "metadata": {},
   "source": [
    "### Questions (3 marks)\n",
    "\n",
    "1. (1 mark) What is the source of your dataset?\n",
    "    The dataset is from Kaggle and is the called the Clustering Penguins Species. Link: https://www.kaggle.com/datasets/youssefaboelwafa/clustering-penguins-species\n",
    "1. (1 mark) Why did you pick this particular dataset?\n",
    "    It seemed like an interesting application of a classification model, seeing if the model can identify different species by the data provided. \n",
    "1. (1 mark) Was there anything challenging about finding a dataset that you wanted to use?\n",
    "    It was fairly easy to find a data set, I just went through kaggle datasets and checked to make sure they had data that would work well for the machine learning models we have been using. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fea4cc",
   "metadata": {},
   "source": [
    "## Step 2: Data Processing (5 marks)\n",
    "\n",
    "The next step is to process your data. Implement the following steps as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "afc244d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "species               0\n",
      "island                0\n",
      "bill_length_mm        2\n",
      "bill_depth_mm         2\n",
      "flipper_length_mm     2\n",
      "body_mass_g           2\n",
      "sex                  11\n",
      "year                  0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.3</td>\n",
       "      <td>20.6</td>\n",
       "      <td>190.0</td>\n",
       "      <td>3650.0</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>Chinstrap</td>\n",
       "      <td>Dream</td>\n",
       "      <td>55.8</td>\n",
       "      <td>19.8</td>\n",
       "      <td>207.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>Chinstrap</td>\n",
       "      <td>Dream</td>\n",
       "      <td>43.5</td>\n",
       "      <td>18.1</td>\n",
       "      <td>202.0</td>\n",
       "      <td>3400.0</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>Chinstrap</td>\n",
       "      <td>Dream</td>\n",
       "      <td>49.6</td>\n",
       "      <td>18.2</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3775.0</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>Chinstrap</td>\n",
       "      <td>Dream</td>\n",
       "      <td>50.8</td>\n",
       "      <td>19.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>4100.0</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>Chinstrap</td>\n",
       "      <td>Dream</td>\n",
       "      <td>50.2</td>\n",
       "      <td>18.7</td>\n",
       "      <td>198.0</td>\n",
       "      <td>3775.0</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>333 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "1       Adelie  Torgersen            39.1           18.7              181.0   \n",
       "2       Adelie  Torgersen            39.5           17.4              186.0   \n",
       "3       Adelie  Torgersen            40.3           18.0              195.0   \n",
       "5       Adelie  Torgersen            36.7           19.3              193.0   \n",
       "6       Adelie  Torgersen            39.3           20.6              190.0   \n",
       "..         ...        ...             ...            ...                ...   \n",
       "340  Chinstrap      Dream            55.8           19.8              207.0   \n",
       "341  Chinstrap      Dream            43.5           18.1              202.0   \n",
       "342  Chinstrap      Dream            49.6           18.2              193.0   \n",
       "343  Chinstrap      Dream            50.8           19.0              210.0   \n",
       "344  Chinstrap      Dream            50.2           18.7              198.0   \n",
       "\n",
       "     body_mass_g     sex  \n",
       "1         3750.0    male  \n",
       "2         3800.0  female  \n",
       "3         3250.0  female  \n",
       "5         3450.0  female  \n",
       "6         3650.0    male  \n",
       "..           ...     ...  \n",
       "340       4000.0    male  \n",
       "341       3400.0  female  \n",
       "342       3775.0    male  \n",
       "343       4100.0    male  \n",
       "344       3775.0  female  \n",
       "\n",
       "[333 rows x 7 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean data (if needed)\n",
    "# Checking for null values\n",
    "print(df.isnull().sum())\n",
    "# Deleting rows with null values\n",
    "df.dropna(inplace=True)\n",
    "df.isnull().sum()\n",
    "# drop year column since its not impactfull on pengiun species\n",
    "df = df.drop(columns='year',axis=1)\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70a8c127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>island_Biscoe</th>\n",
       "      <th>island_Dream</th>\n",
       "      <th>island_Torgersen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>39.3</td>\n",
       "      <td>20.6</td>\n",
       "      <td>190.0</td>\n",
       "      <td>3650.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>1</td>\n",
       "      <td>55.8</td>\n",
       "      <td>19.8</td>\n",
       "      <td>207.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>1</td>\n",
       "      <td>43.5</td>\n",
       "      <td>18.1</td>\n",
       "      <td>202.0</td>\n",
       "      <td>3400.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>1</td>\n",
       "      <td>49.6</td>\n",
       "      <td>18.2</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3775.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>1</td>\n",
       "      <td>50.8</td>\n",
       "      <td>19.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>4100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>1</td>\n",
       "      <td>50.2</td>\n",
       "      <td>18.7</td>\n",
       "      <td>198.0</td>\n",
       "      <td>3775.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>333 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     species  bill_length_mm  bill_depth_mm  flipper_length_mm  body_mass_g  \\\n",
       "1          0            39.1           18.7              181.0       3750.0   \n",
       "2          0            39.5           17.4              186.0       3800.0   \n",
       "3          0            40.3           18.0              195.0       3250.0   \n",
       "5          0            36.7           19.3              193.0       3450.0   \n",
       "6          0            39.3           20.6              190.0       3650.0   \n",
       "..       ...             ...            ...                ...          ...   \n",
       "340        1            55.8           19.8              207.0       4000.0   \n",
       "341        1            43.5           18.1              202.0       3400.0   \n",
       "342        1            49.6           18.2              193.0       3775.0   \n",
       "343        1            50.8           19.0              210.0       4100.0   \n",
       "344        1            50.2           18.7              198.0       3775.0   \n",
       "\n",
       "     sex_female  sex_male  island_Biscoe  island_Dream  island_Torgersen  \n",
       "1           0.0       1.0            0.0           0.0               1.0  \n",
       "2           1.0       0.0            0.0           0.0               1.0  \n",
       "3           1.0       0.0            0.0           0.0               1.0  \n",
       "5           1.0       0.0            0.0           0.0               1.0  \n",
       "6           0.0       1.0            0.0           0.0               1.0  \n",
       "..          ...       ...            ...           ...               ...  \n",
       "340         0.0       1.0            0.0           1.0               0.0  \n",
       "341         1.0       0.0            0.0           1.0               0.0  \n",
       "342         0.0       1.0            0.0           1.0               0.0  \n",
       "343         0.0       1.0            0.0           1.0               0.0  \n",
       "344         1.0       0.0            0.0           1.0               0.0  \n",
       "\n",
       "[333 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implement preprocessing steps. Remember to use ColumnTransformer if more than one preprocessing method is needed\n",
    "# species is the traget vector need to be encoded with label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "df['species'] = label_encoder.fit_transform(df['species'])\n",
    "# colunms sex and island also need to be encoded\n",
    "df = pd.get_dummies(df, columns=['sex','island'],dtype=float)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92c46b7",
   "metadata": {},
   "source": [
    "### Questions (2 marks)\n",
    "\n",
    "1. (1 mark) Were there any missing/null values in your dataset? If yes, how did you replace them and why? If no, describe how you would've replaced them and why.\n",
    "    There were a select number of null values in the data set. There were 2 rows missing data for the majority of the columns and then there was 11 rows missing a value for sex. Since sex is a categorical column, it is very hard to replace the null values with a value that would make sense in the data. Because of this I decided to drop all the rows containing null values. \n",
    "2. (1 mark) What type of data do you have? What preprocessing methods would you have to apply based on your data types?\n",
    "    This data set is a combination of categorical and measurement data. One hot encoding had to be applied to convert the categorical data into numerical data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a245d00",
   "metadata": {},
   "source": [
    "## Step 3: Implement Machine Learning Model (11 marks)\n",
    "\n",
    "In this section, you will implement three different supervised learning models (one linear and two non-linear) of your choice. You will use a pipeline to help you decide which model and hyperparameters work best. It is up to you to select what models to use and what hyperparameters to test. You can use the class examples for guidance. You must print out the best model parameters and results after the grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5558a776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement pipeline and grid search here. Can add more code blocks if necessary\n",
    "# building the pipelines\n",
    "lr_pipeline = Pipeline([('classifier', LogisticRegression(solver='liblinear'))])\n",
    "\n",
    "rf_pipeline = Pipeline([('classifier', RandomForestClassifier(random_state=0))])\n",
    "\n",
    "svm_pipeline = Pipeline([(\"preprocessing\", StandardScaler()),('classifier', SVC(random_state=0))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data\n",
    "X = df.drop('species',axis=1)\n",
    "y = df['species']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessing&#x27;, StandardScaler()),\n",
       "                (&#x27;classifier&#x27;, SVC(random_state=0))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessing&#x27;, StandardScaler()),\n",
       "                (&#x27;classifier&#x27;, SVC(random_state=0))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(random_state=0)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessing', StandardScaler()),\n",
       "                ('classifier', SVC(random_state=0))])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the pipelines \n",
    "lr_pipeline.fit(X_train, y_train)\n",
    "rf_pipeline.fit(X_train,y_train)\n",
    "svm_pipeline.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining parameter grids for each pipeline \n",
    "param_grid_lr = [{'classifier': [LogisticRegression(solver='liblinear')],\n",
    "            'classifier__C': [0.01, 0.1, 1.0, 10.0],\n",
    "            'classifier__fit_intercept': [True, False]\n",
    "             }]\n",
    "\n",
    "param_grid_rf = [{'classifier': [RandomForestClassifier()],\n",
    "            'classifier__n_estimators': [100, 200, 300],\n",
    "            'classifier__max_depth': [1, 2, 3, 5]\n",
    "             }]\n",
    "\n",
    "param_grid_svm = [{'classifier': [SVC()],\n",
    "            'classifier__C': [0.01, 0.1, 1],\n",
    "            'classifier__kernel': [ 'rbf']\n",
    "            }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistical regression best estimator: \n",
      "Pipeline(steps=[('classifier', LogisticRegression(C=0.1, solver='liblinear'))])\n",
      "\n",
      "logistical regression best parameters: \n",
      "{'classifier': LogisticRegression(C=0.1, solver='liblinear'), 'classifier__C': 0.1, 'classifier__fit_intercept': True}\n",
      "\n",
      "Cross-Validation accuracy 0.99\n",
      "Test accuracy 1.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# logistic regression grid search results\n",
    "grid_lr = GridSearchCV(lr_pipeline, param_grid_lr, cv=5)\n",
    "grid_lr.fit(X_train, y_train)\n",
    "\n",
    "print(\"logistical regression best estimator: \")\n",
    "print(str(grid_lr.best_estimator_) + \"\\n\")\n",
    "print(\"logistical regression best parameters: \")\n",
    "print(str(grid_lr.best_params_) + \"\\n\")\n",
    "print(f'Cross-Validation accuracy {grid_lr.best_score_:.2f}')\n",
    "print(f'Test accuracy {grid_lr.score(X_test, y_test):.2f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random forest best estimator: \n",
      "Pipeline(steps=[('classifier', RandomForestClassifier(max_depth=5))])\n",
      "\n",
      "random forest best parameters: \n",
      "{'classifier': RandomForestClassifier(max_depth=5), 'classifier__max_depth': 5, 'classifier__n_estimators': 100}\n",
      "\n",
      "Cross-Validation accuracy 0.99\n",
      "Test accuracy 1.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# random forest grid search results\n",
    "grid_rf = GridSearchCV(rf_pipeline, param_grid_rf, cv=5)\n",
    "grid_rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"random forest best estimator: \")\n",
    "print(str(grid_rf.best_estimator_) + \"\\n\")\n",
    "print(\"random forest best parameters: \")\n",
    "print(str(grid_rf.best_params_) + \"\\n\")\n",
    "print(f'Cross-Validation accuracy {grid_rf.best_score_:.2f}')\n",
    "print(f'Test accuracy {grid_rf.score(X_test, y_test):.2f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random forest best estimator: \n",
      "Pipeline(steps=[('preprocessing', StandardScaler()), ('classifier', SVC(C=1))])\n",
      "\n",
      "random forest best parameters: \n",
      "{'classifier': SVC(C=1), 'classifier__C': 1, 'classifier__kernel': 'rbf'}\n",
      "\n",
      "Cross-Validation accuracy 0.99\n",
      "Test accuracy 1.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM grid search results\n",
    "grid_svm = GridSearchCV(svm_pipeline, param_grid_svm, cv=5)\n",
    "grid_svm.fit(X_train, y_train)\n",
    "\n",
    "print(\"random forest best estimator: \")\n",
    "print(str(grid_svm.best_estimator_) + \"\\n\")\n",
    "print(\"random forest best parameters: \")\n",
    "print(str(grid_svm.best_params_) + \"\\n\")\n",
    "print(f'Cross-Validation accuracy {grid_svm.best_score_:.2f}')\n",
    "print(f'Test accuracy {grid_svm.score(X_test, y_test):.2f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best overall estimator: \n",
      "Pipeline(steps=[('preprocessing', StandardScaler()), ('classifier', SVC(C=1))])\n",
      "\n",
      "best overall parameters: \n",
      "{'classifier': SVC(C=1), 'classifier__C': 1, 'classifier__kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# Putting all three models into gird search to determeine the model and parameters with the lest performance \n",
    "# Defining parameter grids\n",
    "param_grid = [{'classifier': [LogisticRegression(solver='liblinear')],\n",
    "             'classifier__C': [0.01, 0.1, 1.0, 10.0],\n",
    "             'classifier__fit_intercept': [True, False],\n",
    "             'preprocessing': [StandardScaler(), None]},\n",
    "\n",
    "             {'classifier': [RandomForestClassifier()],\n",
    "             'classifier__n_estimators': [100, 200, 300],\n",
    "             'classifier__max_depth': [3, 5, 7, 10, 15],\n",
    "             'preprocessing': [None]},\n",
    "\n",
    "             {'classifier': [SVC()],\n",
    "             'classifier__C': [0.01, 0.1, 1, 10, 100],\n",
    "             'classifier__kernel': ['linear', 'rbf'],\n",
    "             'preprocessing': [StandardScaler(), None]}]\n",
    "\n",
    "grid = GridSearchCV(svm_pipeline, param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"best overall estimator: \")\n",
    "print(str(grid_svm.best_estimator_) + \"\\n\")\n",
    "print(\"best overall parameters: \")\n",
    "print(grid_svm.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbd7075",
   "metadata": {},
   "source": [
    "### Questions (5 marks)\n",
    "\n",
    "1. (1 mark) Do you need regression or classification models for your dataset?\n",
    "    This data set is classifying by species so a classification model was needed. \n",
    "1. (2 marks) Which models did you select for testing and why?\n",
    "    I chose to use a logistical regression model, a random forest model and an SVC model. I chose these models to test a wide variety of models, all three use very different methods to fit the data. I thought this would give me a wide variety of results.  \n",
    "1. (2 marks) Which model worked the best? Does this make sense based on the theory discussed in the course and the context of your dataset?\n",
    "    All the models performed very similarly so it was hard to choose which one work the best. When I put all the models in the same parameter grid and used the best estimator method the result was the SVC model. Since there was no difference in the results when I evaluated the models individually, I chose the best model based on the parameter grid. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f994e31",
   "metadata": {},
   "source": [
    "## Step 4: Validate Model (6 marks)\n",
    "\n",
    "Use the testing set to calculate the testing accuracy for the best model determined in Step 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "69e64c08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate testing accuracy (1 mark)\n",
    "scoring_grid = GridSearchCV(svm_pipeline, param_grid_svm, cv=5, scoring='accuracy')\n",
    "best_model = scoring_grid.fit(X_train, y_train)\n",
    "y_pred = best_model.predict(X_test)\n",
    "acccuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred,  average='weighted')\n",
    "f1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4529ba",
   "metadata": {},
   "source": [
    "\n",
    "### Questions (5 marks)\n",
    "\n",
    "1. (1 mark) Which accuracy metric did you choose? \n",
    "    I chose to use f1 score.\n",
    "1. (1 mark) How do these results compare to those in part 3? Did this model generalize well?\n",
    "    the model preformed very well in both part 3 and 4. The model was able to generalize very well to the test data with a score of 1.0. \n",
    "1. (3 marks) Based on your results and the context of your dataset, did the best model perform \"well enough\" to be used out in the real-world? Why or why not? Do you have any suggestions for how you could improve this analysis?\n",
    "    The model had a prefect test score and an almost prefect training score which indicates that model performed extremely well. The scores were almost too good and could indicate over fitting, however since there isn’t high variance between the test and training scores the high scores may be an indication that the data set is simple and very distinct making it easy to learn and predict. If we look at the scores produced by the other models, we see that every model produced similar scores this also hints that the data set is very easy to learn as different model complexities produced the same results. Before using this model on real world data, I would want to test it on a few more unseen data sets to ensure that the performance is maintained and that the very high scores are not a product of skewed data. Adding more features to the data might make it a more complex and meaningful model.  \n",
    "\n",
    "\n",
    "*ANSWER HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b238f4",
   "metadata": {},
   "source": [
    "## Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "    I used the class examples and the labs to build my code. \n",
    "1. In what order did you complete the steps?\n",
    "    I completed the steps in the laid-out order in the assignment. \n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "    I did not use any AI. \n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?\n",
    "    I had some challenges getting the pipelines to work properly but studying the class examples helped me figure it out.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93097bfe",
   "metadata": {},
   "source": [
    "*DESCRIBE YOUR PROCESS HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd97b6ac",
   "metadata": {},
   "source": [
    "## Reflection (2 marks)\n",
    "Include a sentence or two about:\n",
    "- what you liked or disliked,\n",
    "- found interesting, confusing, challenging, motivating\n",
    "while working on this assignment.\n",
    "\n",
    "I thought it was interesting picking my own data set. It required more thought into what type of data might work well for different models. I found the pipelines confusing at first, especially figuring out how best to do the preprocessing. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
